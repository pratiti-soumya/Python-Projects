{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      " [[4528 3980 2011 ..., 4388 2958 2252]\n",
      " [ 107 3487 4568 ..., 4456 2907 3941]\n",
      " [4500 3566 4302 ..., 1606 3839  712]\n",
      " ..., \n",
      " [2956  361 2258 ...,  103 3233 4681]\n",
      " [2722  719 4827 ..., 4590 3050 1465]\n",
      " [1467 3949 1267 ..., 4570 4557 2761]]\n",
      "(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(0,5000, size=(1000,20))\n",
    "print('X:\\n',X)\n",
    "# print the shape of X\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2475.891  2502.248  2490.535  2471.329  2478.583  2513.14   2457.19\n",
      "  2460.587  2544.502  2486.613  2470.38   2452.59   2484.567  2566.084\n",
      "  2469.616  2501.401  2535.985  2495.27   2471.735  2598.952]\n",
      "[ 1430.34028088  1414.7466001   1437.45271184  1422.69944569  1396.67392942\n",
      "  1436.29274398  1419.05132955  1473.00270143  1450.91549788  1469.95282075\n",
      "  1424.00736992  1424.24544721  1435.64046318  1424.17931629  1403.82478342\n",
      "  1442.93140523  1444.98887151  1434.9616828   1428.89067629  1431.39662068]\n"
     ]
    }
   ],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = X.mean(axis=0)\n",
    "print(ave_cols)\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = X.std(axis=0)\n",
    "print(std_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols.shape)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(std_cols.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.43469986  1.04453476 -0.33360054 ...,  1.31901083  0.34030945\n",
      "  -0.24238705]\n",
      " [-1.65617303  0.69606246  1.44524059 ...,  1.36639885  0.30461743\n",
      "   0.93757941]\n",
      " [ 1.4151241   0.75190285  1.26019102 ..., -0.6197169   0.95687166\n",
      "  -1.31825936]\n",
      " ..., \n",
      " [ 0.33566069 -1.51352051 -0.1617688  ..., -1.66713162  0.53276644\n",
      "   1.45455702]\n",
      " [ 0.17206325 -1.26047166  1.62542043 ...,  1.45978114  0.40469506\n",
      "  -0.79219972]\n",
      " [-0.70535034  1.02262271 -0.85118278 ...,  1.44584348  1.45935937\n",
      "   0.11320971]]\n"
     ]
    }
   ],
   "source": [
    "# Mean normalize X\n",
    "X_norm = (X-ave_cols)/ (std_cols)\n",
    "print(X_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.20792265079e-17\n",
      "-1.74059833266\n",
      "1.7449522205\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(X_norm.mean())\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(X_norm.min(axis=0).mean())\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(X_norm.max(axis=0).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 4, 1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "[168 885 109 243 940 933 318 959 726 504 693 842 197 457 107 781 771 129\n",
      " 191 211 277 391 466 400 403 696 813 329 210 487 749 573 385 798 995 977\n",
      " 855 994 738 735 858 396 229 415 363 316 401 101  91 384 903  18 112 274\n",
      " 330 259 629 554 734  48 851 288 827 614 604 617 427 789  32 422   3 912\n",
      " 595 901 381 142 455  90 841 347 990 314 155 929 373 906 327 423 159 281\n",
      " 537 440 669 196 945 304 656 719 667 106 468  99 102 412 545 957  89 470\n",
      " 174 718 523 145 598 334 856 720 534 140 666 865 306 782 215 390 660 103\n",
      " 502 913 686 754 358 765 668 776 426 743 755  10 592 546 444 496  66 445\n",
      " 209 784 110 867 262 897 248 571 138 796 187  73 287  34 876  71 148 143\n",
      " 624 577 467 594  75 157 411 225 993 938 709 844 939  49 451  51 348 406\n",
      " 687 860  59 216 942 309  78 542  33 915 386 160  95 731 213  52 236 874\n",
      " 887 432 279 231 746 456 917 405  61  85 991 289  36 889 721 862 313 968\n",
      " 863 478 479 907 627 609 433 936 608 838 394 948 801 812 967 697 486 921\n",
      " 320 425 605 883 647 566 958   5 208 418 664 137 135 774 927 190 970 692\n",
      " 141  64  31 795 986 637 714 549 684 387 513 424 658 476 402 376   6 962\n",
      " 407 547 575 238 434  63 147 270 922 237 978 677 848 814 983 563 541   4\n",
      " 510 587 414 179 271 766 799 869 705  19 286 559 448  92 285  74 950 582\n",
      " 493 800 902 894 505 516 245 374 724 952 352 652 108 615 829 323 645 879\n",
      " 672 452 297  62 507 453 295 459 164 201 350 481 603  54 354 388  93 606\n",
      " 834 450 263 258  98 399 985 291 115 460 788 539 822 222 188 884 473 787\n",
      " 778 646 530 973 136 698 442 665 741 283 679 267  28 699 613 707 954 152\n",
      " 875 125 379 982 769  86 421 998 882 599 569 194 337  44 369 806 756 514\n",
      " 845 972 202 969 681 128  80  94 413 252  65 981 923 823 744 847 552 515\n",
      " 529 506 520 525 584  25 996 272 574 265 586 620 975 926 682 343 200 351\n",
      " 280 642 360 836 859 443 302 634 585 797 548 290 932 579 911 673 535 278\n",
      " 311 284 706 949 161 167 900 703 383 621  20 144 924 671 877 791 227 700\n",
      " 702 745 732 275  79  69 428 826 804 648 987 895 896 253 655 908 638 818\n",
      " 689 758 378 465 366 317 610  12 175 640 254 960 930 480 104 266 382  57\n",
      " 308 398 662 184 831 654 158 282 866 362 956 657 815  22 261  84 332 212\n",
      " 312  29 126 590 349 389 246 888 675 934 441 777 150 116 417 463 321 898\n",
      " 325 683 449 713  81 947 750 420 527 177 728 149 185 340 730  60 183 619\n",
      " 130 816 195  50 430  37 593 757 186 123 324 935 533 570 491 941 250 864\n",
      " 206 770 154 240 214 589 944 803 500 484 497 971 528 852 299 458 835 303\n",
      "  83 568 861 853 591 951  87  97 429 134 489 742 292 893 346  40 404 809\n",
      " 688 113  96 817 521 925 872 616 712  24 773 748 630  39 736 849 555 704\n",
      " 319 293 483 223 100 105 556 635 979 768 747 474 131 170 494 805 199 793\n",
      " 676 725 565 597 685 946 540 761 205  45 370 601 663 558 989 729 562 165\n",
      " 694 680  55 611 785 260 790  41 522 733 701 623 307 819 305 891 477 273\n",
      " 298 792 560 961 419 965 342 802 242 508 224 475 931 807 357  70 723 846\n",
      " 810 264 740 173 121 752 618   2 643   1 220 377 310 257   7 550 239 181\n",
      " 580 808 326 192 166 409 840  27 878 914 751 943 918 820 462 492 572 233\n",
      " 471 436 198 300 737 247 328  67 464 868 397  17 127 531 786 490 207 447\n",
      " 628 821 361 717 794 180 193 139 928 632 854 880   9 244 953 345 146 171\n",
      "  53 122 636 825 576 344 439 517   0 241 783 649 339 830 276 578 503 322\n",
      " 976 564  82 625 333 356 437 716 581 234 551 189 857 294 335 837 612 602\n",
      " 353 811 511 955 204 380 485  43  88 690 670  68 873 268 315 780 622 695\n",
      " 482 553 596 715 162 228  11 963 114  58 966 886 588 659  26 850  15 678\n",
      " 904 839 583 372 600 176 509 710 984 301 151 454 762 249 759 518 111 870\n",
      " 892 920  76 767 937 964 501 410 764 824 217 909 230 163  21 156 169  16\n",
      " 833  30 133 235 524  77 905 367 435 365 832 368 828 221  35 495 674 438\n",
      " 543 633 974 364  42 461 739 232  47 532 395 153 651 641  72 919 218 631\n",
      " 512 341 255 772 567 871 890 626 653 226 561  23 916 355 371 992 708 997\n",
      " 119 607 881 124 779 691 446 557 251 269 336 999 760 472 203 727   8 899\n",
      " 775 393 499 538 118 359 172 639 120 722 910 416 338  56 117 408 498 988\n",
      " 256 182 178 763 644 544  46 431  14 519  38 392 219 296 331 469 526 661\n",
      " 650 375 753  13 980 536 488 132 711 843]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "print(X_norm.shape[0])\n",
    "row_indices =np.random.permutation(X_norm.shape[0])\n",
    "print(row_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.33970308 -1.48454006  0.65704074 ...,  1.28207605  1.37327861\n",
      "   0.1278807 ]\n",
      " [-1.0954673   0.94769763  0.94296319 ..., -0.40298637 -0.39942524\n",
      "  -0.36185079]\n",
      " [-0.8430798  -0.39812642 -0.74335315 ...,  0.50923311 -1.58566015\n",
      "  -0.24029119]\n",
      " ..., \n",
      " [ 0.48527543  0.56317647 -1.59764212 ..., -1.14307582 -0.87601873\n",
      "   1.09127546]\n",
      " [ 1.23824311 -1.61247816 -1.44389793 ...,  1.17405922  0.03727717\n",
      "   0.22638589]\n",
      " [-1.70930724 -0.96996027  0.64312724 ..., -0.56117875  1.59932809\n",
      "   1.26732729]]\n"
     ]
    }
   ],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "train_row_indices=row_indices[row_indices>=400]\n",
    "crossval_row_indices=row_indices[(row_indices<400) & (row_indices>=200)]\n",
    "test_row_indices=row_indices[row_indices<200]\n",
    "# Create a Training Set\n",
    "X_train = X_norm[train_row_indices, :]\n",
    "print(X_train)\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X_norm[crossval_row_indices, :]\n",
    "\n",
    "# Create a Test Set\n",
    "X_test =X_norm[test_row_indices, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 20)\n",
      "(200, 20)\n",
      "(200, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print(X_train.shape)\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "\n",
    "print(X_crossVal.shape)\n",
    "# Print the shape of X_test\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
